{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67340de4-6b52-48fa-8cc1-eb1ec67069e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils import get_yaml_value, parameter, create_dir, save_feature_network\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "classes = get_yaml_value(\"classes\")\n",
    "batchsize = get_yaml_value(\"batch_size\")\n",
    "\n",
    "data_dir = get_yaml_value(\"dataset_path\")\n",
    "image_size = get_yaml_value(\"image_size\")\n",
    "\n",
    "name_rank = []\n",
    "with open(\"query_drone_name.txt\", \"r\") as f:\n",
    "    for txt in f.readlines():\n",
    "        name_rank.append(txt[:-1])\n",
    "\n",
    "class CustomImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, file_list, transform=None, target_transform=None):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.samples = self._make_dataset(file_list)\n",
    "        # print(self.samples)\n",
    "\n",
    "    def _make_dataset(self, file_list):\n",
    "        data = []\n",
    "        for line in file_list:\n",
    "            path = os.path.join(self.root,\"query_drone_160k\" ,line)\n",
    "            item = (path, int(0))\n",
    "            data.append(item)\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "transform_test_list = [\n",
    "        transforms.Resize((image_size, image_size), interpolation=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "data_transforms = {\n",
    "    'drone': transforms.Compose(transform_test_list),\n",
    "    'satellite': transforms.Compose(transform_test_list)}\n",
    "image_datasets = {}\n",
    "\n",
    "image_datasets['satellite'] = datasets.ImageFolder(os.path.join(\"/root\", 'autodl-tmp', 'Gallery'),\n",
    "                                                   data_transforms['satellite'])\n",
    "image_datasets['drone'] = CustomImageFolder(os.path.join(\"/root\", 'autodl-tmp', 'Query'),name_rank,\n",
    "                                               data_transforms['drone'])\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=False, num_workers=8, pin_memory=True)              \n",
    "               for x in ['satellite', 'drone']}\n",
    "with open('query_drone_name.txt', 'r') as f:\n",
    "    order = [line.strip() for line in f.readlines()]\n",
    "image_datasets['drone'].imgs = sorted(image_datasets['drone'].imgs, key=lambda x: order.index(x[0].split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6ccc61-49ba-490c-9c29-256e82837c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import model_\n",
    "net_path = \"/root/autodl-tmp/weights/Modern_1652_2023-06-22-04:19:58/net_059.pth\"\n",
    "model = model_.EVA(701, 0.1).cuda()\n",
    "model.load_state_dict(torch.load(net_path))\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e05671-ef72-4683-a41d-c06921b9aa3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fliplr(img):\n",
    "    '''flip horizontal'''\n",
    "    inv_idx = torch.arange(img.size(3) - 1, -1, -1).long()  # N x C x H x W\n",
    "    img_flip = img.index_select(3, inv_idx)\n",
    "    return img_flip\n",
    "\n",
    "# print(gallery_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6858a69-7bfe-43b3-9554-432a36dc4096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "import numpy as np\n",
    "import time\n",
    "def extract_feature(model, dataloaders, block, LPN, view_index=1):\n",
    "    features = torch.FloatTensor()\n",
    "    count = 0\n",
    "    for data in dataloaders:\n",
    "        img, label = data\n",
    "        n, c, h, w = img.size()\n",
    "        count += n\n",
    "\n",
    "        if LPN:\n",
    "            ff = torch.FloatTensor(n, 512, block).zero_().cuda()\n",
    "        else:\n",
    "            ff = torch.FloatTensor(n, 512).zero_().cuda()\n",
    "\n",
    "        # why for in range(2)：\n",
    "        # 1. for flip img\n",
    "        # 2. for normal img\n",
    "\n",
    "        for i in range(2):\n",
    "            if i == 1:\n",
    "                img = fliplr(img)\n",
    "\n",
    "            input_img = img.to(device)\n",
    "            outputs = None\n",
    "            since = time.time()\n",
    "\n",
    "            if view_index == 1:\n",
    "                outputs, _ = model(input_img, None)\n",
    "            elif view_index == 2:\n",
    "                _, outputs = model(None, input_img)\n",
    "            # print(outputs.shape)\n",
    "            # print(ff.shape)\n",
    "            ff += outputs\n",
    "            time_elapsed = time.time() - since\n",
    "            # print(time_elapsed)\n",
    "            # ff.shape = [16, 512, 4]\n",
    "\n",
    "        if LPN:\n",
    "            fnorm = torch.norm(ff, p=2, dim=1, keepdim=True) * np.sqrt(block)\n",
    "            # print(\"fnorm\", fnorm.shape)\n",
    "            ff = ff.div(fnorm.expand_as(ff))\n",
    "            # print(\"ff\", ff.shape)\n",
    "            ff = ff.view(ff.size(0), -1)\n",
    "            # print(\"ff\", ff.shape)\n",
    "        else:\n",
    "            fnorm = torch.norm(ff, p=2, dim=1, keepdim=True)\n",
    "            # print(\"fnorm\", fnorm.shape)\n",
    "            ff = ff.div(fnorm.expand_as(ff))\n",
    "            # print(\"ff\", ff.shape)\n",
    "\n",
    "        features = torch.cat((features, ff.data.cpu()), 0)  # 在维度0上拼接\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b2982-1b83-4691-9b75-56653803be47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_feature\n"
     ]
    }
   ],
   "source": [
    "def get_SatId_160k(img_path):\n",
    "    labels = []\n",
    "    paths = []\n",
    "    for path,v in img_path:\n",
    "        labels.append(v)\n",
    "        paths.append(path)\n",
    "    return labels, paths\n",
    "\n",
    "def get_result_rank10(qf,gf,gl):\n",
    "    query = qf.view(-1,1)\n",
    "    score = torch.mm(gf, query)\n",
    "    score = score.squeeze(1).cpu()\n",
    "    score = score.numpy()\n",
    "    index = np.argsort(score)\n",
    "    index = index[::-1]\n",
    "    rank10_index = index[0:10]\n",
    "    result_rank10 = gl[rank10_index]\n",
    "    return result_rank10\n",
    "\n",
    "query_feature = extract_feature(model, dataloaders[\"drone\"], 2, 0, 2)\n",
    "print(\"query_feature\")\n",
    "gallery_feature = extract_feature(model, dataloaders[\"satellite\"], 2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61416af0-309a-4247-84bc-045da4dcbbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_img_list = image_datasets[\"drone\"].imgs\n",
    "gallery_img_list = image_datasets[\"satellite\"].imgs\n",
    "\n",
    "result = {}\n",
    "for i in range(len(query_img_list)):\n",
    "    \n",
    "    query = query_feature[i].view(-1, 1)\n",
    "    score = torch.mm(gallery_feature, query)\n",
    "    score = score.squeeze(1).cpu()\n",
    "    index = np.argsort(score.numpy())\n",
    "    index = index[::-1].tolist()\n",
    "    max_score_list = index[0:10]\n",
    "    query_img = query_img_list[i][0]\n",
    "    most_correlative_img = []\n",
    "    for index in max_score_list:\n",
    "        most_correlative_img.append(gallery_img_list[index][0])\n",
    "    result[query_img] = most_correlative_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa91fce-7f8b-4df8-b39c-5851930ee588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "matching_table = pd.DataFrame(result)\n",
    "print(matching_table)\n",
    "matching_table.to_csv(\"result.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c1e204-f252-4597-8056-8f0a0394f16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
